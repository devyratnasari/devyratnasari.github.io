<!DOCTYPE HTML>
<!--
	Solid State by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<link rel="icon" type="image/x-icon" href="../assets/css/images/title.png">
		<title>Credit Card Frauds</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />
		<noscript><link rel="stylesheet" href="../assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Page Wrapper -->
			<div id="page-wrapper">

				<!-- Header -->
				<header id="header">
					<h1><a href="../index.html">Devy Ratnasari</a></h1>
					<nav>
						<a href="#menu">On This Page</a>
					</nav>
				</header>

				<!-- Menu -->
				<nav id="menu">
					<div class="inner">
						<h2>On This Page</h2>
						<ul class="links">
							<li><a href="../index.html">Home</a></li>
							<li><a href="#eda">EDA & Preprocessing</a>
							</li>
							<li>
								<div class="dropdown">
									<a href="#logreg1">Models</a>
									<div class="dropdown-content">
										<a href="#svm">Support Vector Machine</a>
										<a href="#lr">Logistic Regression</a>
										<a href="#rf">Random Forest</a>
										<a href="#dt">Decision Tree</a>
										<a href="#knn">K-Nearest Neighbor</a>

										<a href="#ann">Artificial Neural Network</a>
										<a href="#cnn">Convolutional Neural Network</a>
									</div>
								</div>
							</li>
							<li><a href="#conclusion">Conclusion</a></li>
							<li><a href="../ml.html">Back to projects</a></li>
						</ul>
						<a href="#" class="close">Close</a>
					</div>
				</nav>

				<!-- Wrapper -->
					<section id="wrapper">
						<header>
							<div class="inner">
								<h2>Credit Card Fraud Detection</h2>
								<p>This is a group project from Durham College Capstone 1.
									Team members: Devy Ratnasari, Priyanka Singh,  Gopika Shaji, Oluwole Ayodele, and Saurav Bisht.
									We used 5 different machine learning and 2 deep learning algorithms to classify transactions into fraud vs non-fraud.
The datasets are dummy data from Kaggle and it has been split into 2 files, Train and Test.
We combined 2 datasets to see the total number of data and the balance percentage before splitting it into train and test datasets.


</p>
<ul class="actions">
	<li><a href="https://www.youtube.com/watch?v=i9DjmUWxTlg" class="button">Youtube Presentation</a></li>
	<li><a href="../visual/capstone1.html" class="button">Tableau Story</a></li>
</ul>


							</div>
						</header>

						<!-- Content -->
							<div class="wrapper">
								<div class="inner">

									<h2 class="major" id="eda">EDA & Data Preprocessing</h3>
									<p>Exploratory Data Analysis is one of the major step to fine-tune the given dataset and performing data analysis to understand the insights of the key characteristics of various entities of the data set like column(s), row(s) by applying Pandas, NumPy, Statistical Methods, and Data visualization packages. 

										Outcome of this phase are: 
										<ol>
											<li>Understanding and cleaning the given dataset.</li>
											<li>Understanding relationship between different features or columns and target variable.</li>
											<li>Provide guidelines for essential variables vs non-essential variables.</li>
											<li>Handling Missing values or human error.</li>
											<li>Identifying outliers.</li>
										</ol>
									</p>
									<pre><code>#import the train dataset
dtrain = pd.read_csv('../dataset/fraudTrain.csv')

#import the test dataset
dtest = pd.read_csv('../dataset/fraudTest.csv')

#combine 2 datasets into 1
fullset = pd.concat([dtrain, dtest])

#delete the original data before merge to save memory
del dtrain, dtest

#see the structure of data
print(fullset.shape)
print(fullset.info())

#print sample of data(the first 5 rows)
fullset.head()</code>
	(1852394, 23)
	Int64../index: 1852394 entries, 0 to 555718
	Data columns (total 23 columns):
	#   Column                 Dtype  
	---  ------                 -----  
	0   Unnamed: 0             int64  
	1   trans_date_trans_time  object 
	2   cc_num                 int64  
	3   merchant               object 
	4   category               object 
	5   amt                    float64
	6   first                  object 
	7   last                   object 
	8   gender                 object 
	9   street                 object 
	10  city                   object 
	11  state                  object 
	12  zip                    int64  
	13  lat                    float64
	14  long                   float64
	15  city_pop               int64  
	16  job                    object 
	17  dob                    object 
	18  trans_num              object 
	19  unix_time              int64  
	20  merch_lat              float64
	21  merch_long             float64
	22  is_fraud               int64  
	dtypes: float64(5), int64(6), object(12)</pre>
<div class="table-wrapper">
	<table>
		<thead>
			<tr style="text-align: right;">
			  <th></th>
			  <th>Unnamed: 0</th>
			  <th>trans_date_trans_time</th>
			  <th>cc_num</th>
			  <th>merchant</th>
			  <th>category</th>
			  <th>amt</th>
			  <th>first</th>
			  <th>last</th>
			  <th>gender</th>
			  <th>street</th>
			  <th>...</th>
			  <th>lat</th>
			  <th>long</th>
			  <th>city_pop</th>
			  <th>job</th>
			  <th>dob</th>
			  <th>trans_num</th>
			  <th>unix_time</th>
			  <th>merch_lat</th>
			  <th>merch_long</th>
			  <th>is_fraud</th>
			</tr>
		  </thead>
		  <tbody>
			<tr>
			  <th>0</th>
			  <td>0</td>
			  <td>2019-01-01 00:00:18</td>
			  <td>2703186189652095</td>
			  <td>fraud_Rippin, Kub and Mann</td>
			  <td>misc_net</td>
			  <td>4.97</td>
			  <td>Jennifer</td>
			  <td>Banks</td>
			  <td>F</td>
			  <td>561 Perry Cove</td>
			  <td>...</td>
			  <td>36.0788</td>
			  <td>-81.1781</td>
			  <td>3495</td>
			  <td>Psychologist, counselling</td>
			  <td>1988-03-09</td>
			  <td>0b242abb623afc578575680df30655b9</td>
			  <td>1325376018</td>
			  <td>36.011293</td>
			  <td>-82.048315</td>
			  <td>0</td>
			</tr>
			<tr>
			  <th>1</th>
			  <td>1</td>
			  <td>2019-01-01 00:00:44</td>
			  <td>630423337322</td>
			  <td>fraud_Heller, Gutmann and Zieme</td>
			  <td>grocery_pos</td>
			  <td>107.23</td>
			  <td>Stephanie</td>
			  <td>Gill</td>
			  <td>F</td>
			  <td>43039 Riley Greens Suite 393</td>
			  <td>...</td>
			  <td>48.8878</td>
			  <td>-118.2105</td>
			  <td>149</td>
			  <td>Special educational needs teacher</td>
			  <td>1978-06-21</td>
			  <td>1f76529f8574734946361c461b024d99</td>
			  <td>1325376044</td>
			  <td>49.159047</td>
			  <td>-118.186462</td>
			  <td>0</td>
			</tr>
			<tr>
			  <th>2</th>
			  <td>2</td>
			  <td>2019-01-01 00:00:51</td>
			  <td>38859492057661</td>
			  <td>fraud_Lind-Buckridge</td>
			  <td>entertainment</td>
			  <td>220.11</td>
			  <td>Edward</td>
			  <td>Sanchez</td>
			  <td>M</td>
			  <td>594 White Dale Suite 530</td>
			  <td>...</td>
			  <td>42.1808</td>
			  <td>-112.2620</td>
			  <td>4154</td>
			  <td>Nature conservation officer</td>
			  <td>1962-01-19</td>
			  <td>a1a22d70485983eac12b5b88dad1cf95</td>
			  <td>1325376051</td>
			  <td>43.150704</td>
			  <td>-112.154481</td>
			  <td>0</td>
			</tr>
			<tr>
			  <th>3</th>
			  <td>3</td>
			  <td>2019-01-01 00:01:16</td>
			  <td>3534093764340240</td>
			  <td>fraud_Kutch, Hermiston and Farrell</td>
			  <td>gas_transport</td>
			  <td>45.00</td>
			  <td>Jeremy</td>
			  <td>White</td>
			  <td>M</td>
			  <td>9443 Cynthia Court Apt. 038</td>
			  <td>...</td>
			  <td>46.2306</td>
			  <td>-112.1138</td>
			  <td>1939</td>
			  <td>Patent attorney</td>
			  <td>1967-01-12</td>
			  <td>6b849c168bdad6f867558c3793159a81</td>
			  <td>1325376076</td>
			  <td>47.034331</td>
			  <td>-112.561071</td>
			  <td>0</td>
			</tr>
			<tr>
			  <th>4</th>
			  <td>4</td>
			  <td>2019-01-01 00:03:06</td>
			  <td>375534208663984</td>
			  <td>fraud_Keeling-Crist</td>
			  <td>misc_pos</td>
			  <td>41.96</td>
			  <td>Tyler</td>
			  <td>Garcia</td>
			  <td>M</td>
			  <td>408 Bradley Rest</td>
			  <td>...</td>
			  <td>38.4207</td>
			  <td>-79.4629</td>
			  <td>99</td>
			  <td>Dance movement psychotherapist</td>
			  <td>1986-03-28</td>
			  <td>a41d7549acf90789359a9aa5346dcb46</td>
			  <td>1325376186</td>
			  <td>38.674999</td>
			  <td>-78.632459</td>
			  <td>0</td>
			</tr>
		  </tbody>
	</table>
</div>
<pre><code>#convert dob to age
fullset['dob'] = pd.to_datetime(fullset.dob)
def from_dob_to_age(born):
	today = datetime.date.today()
	return today.year - born.year - ((today.month, today.day) < (born.month, born.day))

fullset['Age']=fullset['dob'].apply(lambda x: from_dob_to_age(x))
</code></pre>
<div class="desc">Letâ€™s visualize if there is any relationship between the target variable and Age.
	Visualize relationship between is_fraud and age. We can see that majority of fraud happened between age 37 to 65.
	</div>
	<pre><code>fig= plt.figure(figsize=(10,5) )
fig.add_subplot(1,3,1)
ar_6=sns.boxplot(x=fullset["is_fraud"],y=fullset["Age"])</code></pre>
<div class="center"><img src="../images/frauds/boxplot-age.png" alt=""></div>
<div class="desc">Then we will check if there is any null value in the dataset.</div>
<pre><code>fullset.isna().sum()</code>
	Unnamed: 0               0
	trans_date_trans_time    0
	cc_num                   0
	merchant                 0
	category                 0
	amt                      0
	first                    0
	last                     0
	gender                   0
	street                   0
	city                     0
	state                    0
	zip                      0
	lat                      0
	long                     0
	city_pop                 0
	job                      0
	dob                      0
	trans_num                0
	unix_time                0
	merch_lat                0
	merch_long               0
	is_fraud                 0
	Age                      0</pre>
	<div class="desc">Checking for unique values in the dataset</div>
	<pre><code>for col in fullset:
	uValue = np.unique(fullset[col])
	rValue = len(uValue)
	if rValue < 50:
		print('Unique values {} total {} --{}'.format(col, rValue, uValue))
	else:
		print('Unique Value {} -- {}'.format(col, rValue))</code>
		Unique Value Unnamed: 0 -- 1296675
		Unique values trans_date_trans_time total 24 --[Period('2019-01', 'M') Period('2019-02', 'M') Period('2019-03', 'M')
		 Period('2019-04', 'M') Period('2019-05', 'M') Period('2019-06', 'M')
		 Period('2019-07', 'M') Period('2019-08', 'M') Period('2019-09', 'M')
		 Period('2019-10', 'M') Period('2019-11', 'M') Period('2019-12', 'M')
		 Period('2020-01', 'M') Period('2020-02', 'M') Period('2020-03', 'M')
		 Period('2020-04', 'M') Period('2020-05', 'M') Period('2020-06', 'M')
		 Period('2020-07', 'M') Period('2020-08', 'M') Period('2020-09', 'M')
		 Period('2020-10', 'M') Period('2020-11', 'M') Period('2020-12', 'M')]
		Unique Value cc_num -- 999
		Unique Value merchant -- 693
		Unique values category total 14 --['entertainment' 'food_dining' 'gas_transport' 'grocery_net' 'grocery_pos'
		 'health_fitness' 'home' 'kids_pets' 'misc_net' 'misc_pos' 'personal_care'
		 'shopping_net' 'shopping_pos' 'travel']
		Unique Value amt -- 60616
		Unique Value first -- 355
		Unique Value last -- 486
		Unique values gender total 2 --['F' 'M']
		Unique Value street -- 999
		Unique Value city -- 906
		Unique Value state -- 51
		Unique Value zip -- 985
		Unique Value lat -- 983
		Unique Value long -- 983
		Unique Value city_pop -- 891
		Unique Value job -- 497
		Unique Value dob -- 984
		Unique Value trans_num -- 1852394
		Unique Value unix_time -- 1819583
		Unique Value merch_lat -- 1754157
		Unique Value merch_long -- 1809753
		Unique values is_fraud total 2 --[0 1]
		Unique Value Age -- 80</pre>
		<div class="desc">We want to see the amount of fraud that happening from January 2019 to December 2020. </div>
		<pre><code>fraud = fullset.query('is_fraud == 1')  
fraud['trans_date_trans_time'].value_counts().sort_../index().plot()
plt.title('Fraud growths')</code></pre>
<div class="center"><img src="../images/frauds/fraud-growth.png" alt=""></div>
<div class="desc">It seems, the fraud peaking during the holiday season. We want to see what is category the most targeted by the fraudster.</div>
<pre><code>sns.countplot(y=fraud.category, data=fraud, palette = 'Set3')
plt.title('Fraud Category')
plt.xlabel('Total')
plt.show()</code></pre>
<div class="center"><img src="../images/frauds/fraud-category.png" alt=""></div>
<div class="desc">From the graph above, we can see most of the fraud happening through online shopping and grocery point-of-sale networks. Then we want to see the percentage of positive and negative fraud transactions.</div>

<pre><code>print(fullset['is_fraud'].value_counts())
	#visual the imbalanced data using charts
	fig= plt.figure(figsize=(10,5) )
	fig.add_subplot(1,2,1)
	explode = [0, 0.5]
	#labels = ['Fraud', 'Non-Fraud']
	a= fullset["is_fraud"].value_counts(normalize=True).plot.pie(explode=explode, autopct='%1.1f%%')
	fig.add_subplot(1,2,2)
	churnchart=sns.countplot(x=fullset["is_fraud"])
	plt.tight_layout()
	plt.show()</code>
	0    1842743
	1       9651</pre>
<div class="center"><img src="../images/frauds/pie-target.png" alt=""></div>
<div class="desc">The imbalanced ratio is 99.47:0.52 which means that our dataset is highly imbalanced where majority of transactions are legitimate transactions and very few are fraudulent transactions.
	The machine learning model trained on this data may yield high overall prediction towards majority class since 99.47% samples belong to majority class or class 0.
	Since our dataset is huge, we treated class imbalance problem using random under-sampling techinque from imblearn. <br>
	We want to check the distribution of our data using the histogram.
</div>
<pre><code>p = fullset.hist(figsize = (15,15))</code></pre>
<div class="center"><img src="../images/frauds/histogram.png" alt=""></div>
<div class="desc">We will convert our non numerical dataset to numerical then plot the correlation matrix to see the correlation between each features.</div>
<pre><code>#apply label encoder to the dataset and put in the new dataset
newset = fullset.apply(LabelEncoder().fit_transform)

#plot correlation matrix
fig, ax = plt.subplots(figsize=(25,10))  
sns.heatmap(newset.corr(), annot = True, ax=ax, cmap = 'Blues')
plt.title("DataCorrelation")
plt.show()</code></pre>
<div class="center"><img src="../images/frauds/corr-matrix.png" alt=""></div>
<div class="desc">We will be dropping is_fraud because we will use it as our y axis and dropping variables which are highly correlated like merch_lat and merch_long</div>
<pre><code>dropvar = ['is_fraud','Unnamed: 0', 'first', 'last', 'dob', 'trans_date_trans_time','trans_num', 'merch_lat', 'merch_long'] 
#create our dependent variables
x = newset.drop(dropvar, axis=1).copy()

#independent variable
y = newset['is_fraud'].copy()</code></pre>
<h2 class="major" id="undersampler">Random Under Sampler</h2>
<p>Undersampling is a technique to balance uneven datasets by keeping all of the data in the minority class and decreasing the size of the majority class. It is one of several techniques data scientists can use to extract more accurate information from originally imbalanced datasets.
<br>	Since our dataset is highly imbalance, we keep all the data of fraud class and decrease the samples from the non-fraud class.</p>
<pre><code>#import library for random under sampler
import imblearn
from imblearn.under_sampling import RandomUnderSampler
import collections
from collections import Counter

#calling the method and fit it with x and y data
unSampler = RandomUnderSampler(random_state=42, replacement=True)
xund, yund = unSampler.fit_resample(x,y)

print('original dataset shape:', Counter(y))
print('resample dataset shape', Counter(yund))</code>
	original dataset shape: Counter({0: 1842743, 1: 9651})
	resample dataset shape Counter({0: 9651, 1: 9651})</pre>
	<pre><code>#visual the balanced data using bar chart
underfraud = pd.DataFrame(yund)
sns.countplot(x = 'is_fraud', data = underfraud)
plt.show()</code></pre>
<div class="center"><img src="../images/frauds/undersampler.png" alt=""></div>
<div class="desc">After we implement Random Under Sampler, our target observation become 19302 rows.
	<br>We will scale our data and perform PCA to reduce the dimensionality.
</div>
<pre><code>#scaling the data
mmscale = MinMaxScaler()
#transform the values
X_scaled = mmscale.fit_transform(xund)
from sklearn.decomposition import PCA
pca_15 = PCA(n_components = 15, random_state=2020)
pca_15.fit(X_scaled)
X_pca_15 = pca_15.transform(X_scaled)
#create following plot

plt.plot(np.cumsum(pca_15.explained_variance_ratio_))
plt.xlabel('Number of components')
plt.ylabel('Explained variance')
plt.savefig('elbow_plot.png', dpi= 100)</code></pre>
<div class="center"><img src="../images/frauds/pcs.png" alt=""></div>

<div class="desc">From the chart above, it shows that the best number of features are 14. </div>
<pre>Function for metrix evaluation
<code>score= []

#plot confusion matrixfrom sklearn.metrics import ConfusionMatrixDisplay, accuracy_score
from sklearn.metrics import log_loss, confusion_matrix, roc_auc_score, roc_curve

#plot the confusion matrix
def cm(algo): #it need the model variable after fitting the data
    disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(ytest, algo.predict(xtest)),
                           display_labels=algo.classes_)
    disp.plot()
    plt.show()

#print metrix score
#function to print metrics score
def prints(cmatrix, acctest, acctrain, overfit, logtest, logtrain, precision1,
                  precision0, recall1, recall0, f1, roctest, roctrain):
    print("Confusion Matrix Accuracy Score = {:.2f}%\n".format(cmatrix))
    print("Accuracy Score: Training -> {:.2f}% Testing -> {:.2f}%\n".format(acctrain, acctest))
    print("Overfitting : {:.2f}%".format(overfit))
    print("Log Loss Training-> {} Testing -> {}\n".format(logtrain, logtest))
    print('Precision class 1: {:.2f}%\nPrecision class 0: {:.2f}%'.format(precision1, precision0))
    print('Recall class 1: {:.2f}%\nRecall class 0: {:.2f}%'.format(recall1, recall0))
    print('F1: {:.2f}%'.format(f1)) 
    print('ROC AUC Training-> {:.2f}% Testing-> {:.2f}%'.format(roctrain, roctest))

#function add metrics score to list
def insertlist(name, cmatrix, acctest, acctrain,overfit, logtest, logtrain, precision1,
					precision0, recall1, recall0, f1, roctest, roctrain):
	score.append([name, cmatrix, acctest, acctrain,overfit, logtest, logtrain, precision1,
					precision0, recall1, recall0, f1, roctest, roctrain])

# Plot Roc Curve
def auc_plot(algo):
	#create AUC curve
	test_prob = algo.predict_proba(xtest)[::,1]
	train_prob = algo.predict_proba(xtrain)[::,1]
	roctest = roc_auc_score(ytest, test_prob)
	roctrain = roc_auc_score(ytrain, train_prob)
	
	fpr_test, tpr_test, _ = roc_curve(ytest,  test_prob)
	fpr_train, tpr_train, _ = roc_curve(ytrain,  train_prob)
	plt.title("Area Under Curve")
	plt.plot(fpr_test,tpr_test,label="AUC Test="+str(roctest))
	plt.plot(fpr_train,tpr_train,label="AUC Train="+str(roctrain))
	plt.ylabel('True Positive Rate')
	plt.xlabel('False Positive Rate')
	plt.legend(loc=4)
	plt.grid(True)
	plt.show()		

#metrix function 
def scr(algo, name): #algo = model, name = string of the model name
	predtest = algo.predict(xtest)
	predtrain = algo.predict(xtrain)
	
	#confussion matrix percentage
	tn, fp, fn, tp = confusion_matrix(ytest, predtest).ravel()
	tst = ytest.count()
	cmatrix = ((tn + tp)/tst)*100    

	#accuracy score
	acctest = (accuracy_score(ytest, predtest))*100
	acctrain = (accuracy_score(ytrain, predtrain))*100
	overfit = acctrain - acctest

	#log loss
	logtest = log_loss(ytest,predtest)
	logtrain = log_loss(ytrain,predtrain)
			
	#classification report
	precision1 = (tp / (tp+fp))*100
	precision0 = (tn/(tn+fn))*100
	recall1 = (tp/(tp+fn))*100
	recall0 = (tn/(tn+fp))*100
	f1 = 2*(precision1 * recall1)/(precision1 + recall1)

	#roc auc score
	test_prob = algo.predict_proba(xtest)[::,1]
	train_prob = algo.predict_proba(xtrain)[::,1]
	roctest = (roc_auc_score(ytest, test_prob))*100
	roctrain = (roc_auc_score(ytrain, train_prob))*100

	insertlist(name, cmatrix, acctest, acctrain, overfit, logtest, logtrain, precision1,
				precision0, recall1, recall0, f1, roctest, roctrain)      
	#print metrics score
	return prints(cmatrix, acctest, acctrain, overfit, logtest, logtrain, precision1,
					precision0, recall1, recall0, f1, roctest, roctrain)
</code></pre>
<div class="desc">Split our dataset into training and testing</div>
<pre><code>xtrain, xtest, ytrain, ytest = train_test_split(x_pca, yund, test_size=0.3, random_state=42)</code></pre>
<h2 class="major" id="svm">Model 1 - Support Vector Machine</h2>
<pre><code>from sklearn.svm import SVC

#build SVM classification
SVM1 = SVC(random_state = 42, probability=True)
SVM1.fit(xtrain, ytrain)
scr(SVM1, 'SVM1')
cm(SVM1)
auc_plot(SVM1)
</code>
	Confusion Matrix Accuracy Score = 86.22%

	Accuracy Score: Training -> 86.94% Testing -> 86.22%

	Overfitting : 0.72%
	Log Loss Training-> 4.511955968344787 Testing -> 4.759453002690722

	Precision class 1: 97.25%
	Precision class 0: 79.36%
	Recall class 1: 74.55%
	Recall class 0: 97.89%
	F1: 84.40%
	ROC AUC Training-> 91.93% Testing-> 88.39%</pre>
	<div class="center"><img src="../images/frauds/cm-svm.png" alt="" class="vis"><img src="../images/frauds/roc-svm.png" alt="" class="vis"></div>
	<div class="desc">From the confusion matrix, the accuracy score is 86.22%.
		Next, we will try to improve the prediction using cross validation to optimise the hyperparameters.
		Cross-validation systematically creates and evaluates multiple models on multiple subsets of the dataset.</div>
	<pre><code>kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
param_grid = [
	{
		'C': [1, 10, 15, 20, 25, 30], 
		'gamma': ['scale', 0.001, 0.01],
		'kernel': ['rbf','linear','sigmoid']
	},
]

#tuning the model using gridsearchCV and stratifiedkfold
optimal_param = GridSearchCV(
	SVC(), param_grid, cv=kfold, scoring='accuracy', verbose = 2)
	#fitting the tuned model with training dataset
optimal_param.fit(xtrain, ytrain)

#print the best parameter
print(optimal_param.best_params_)
		</code>
	{'C': 15, 'gamma': 'scale', 'kernel': 'rbf'}</pre>
<pre><code>#build the model with hyperparameter tuning
optimal_param = SVC(random_state = 42, probability=True, C=20, gamma='scale', kernel='rbf')
optimal_param.fit(xtrain,ytrain)
#print metrics score
scr(optimal_param, 'SVM_tuned')
#plot confusion matrix for the tuned model
cm(optimal_param)
#plot the learning curve
auc_plot(optimal_param)</code>
	Confusion Matrix Accuracy Score = 87.65%

	Accuracy Score: Training -> 93.07% Testing -> 87.65%

	Overfitting : 5.42%
	Log Loss Training-> 2.392745485940981 Testing -> 4.26443851713289

	Precision class 1: 93.15%
	Precision class 0: 83.39%
	Recall class 1: 81.28%
	Recall class 0: 94.02%
	F1: 86.82%
	ROC AUC Training-> 97.61% Testing-> 93.11%</pre>
<div class="center"><img src="../images/frauds/cm-svm-tuned.png" alt="" class="vis"><img src="../images/frauds/roc-svm-tuned.png" alt="" class="vis"></div>
<div class="desc">Before Tuning Accuracy Score - 86.22%
<br>After Tuning Accuracy score is 87.71%
<br>However, model is slightly overfit after hypertuning.</div>
<h2 class="major" id="lr">Model 2 - Logistic Regression</h2>
<pre><code>#create logistic regression model
logreg = LogisticRegression()
#fitting the model with training dataset
logreg.fit(xtrain, ytrain)
scr(logreg, 'Logreg')
cm(logreg)
auc_plot(logreg)</code>
	Confusion Matrix Accuracy Score = 84.63%

	Accuracy Score: Training -> 85.06% Testing -> 84.63%

	Overfitting : 0.43%
	Log Loss Training-> 5.15872999693614 Testing -> 5.308178710927689

	Precision class 1: 92.04%
	Precision class 0: 79.44%
	Recall class 1: 75.83%
	Recall class 0: 93.44%
	F1: 83.15%
	ROC AUC Training-> 85.19% Testing-> 84.35%</pre>
	<div class="center"><img src="../images/frauds/cm-lr.png" alt="" class="vis"><img src="../images/frauds/roc-lr.png" alt="" class="vis"></div>
	<div class="desc">The accuracy score is 84.63%, it's lower compared to SVM.
		We will tune the model using grid search cross validation.</div>
		<pre><code>log_param = [
	{
		'C': [0.01, 0.1, 1.0, 10, 100], 
		'penalty': ['l2'],
		'solver': ['newton-cg', 'sag','saga'] 
	},
]

#tuned the model using gridsearch and kfold
opt_log = GridSearchCV(LogisticRegression(), param_grid = log_param, scoring='accuracy', cv=kfold, verbose = 2)

#fit the tuned model with training dataset
opt_log.fit(xtrain, ytrain) 
print(opt_log.best_params_)</code>
	{'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}</pre>
<pre><code>opt_log = LogisticRegression(random_state = 42, C=0.012, penalty = 'l2', solver = 'sag' )
opt_log.fit(xtrain, ytrain)
scr(opt_log, 'logreg_tuned')
cm(opt_log)
auc_plot(opt_log)</code>
	Confusion Matrix Accuracy Score = 85.17%

	Accuracy Score: Training -> 85.54% Testing -> 85.17%

	Overfitting : 0.37%
	Log Loss Training-> 4.9951177071719135 Testing -> 5.123281655199142

	Precision class 1: 93.81%
	Precision class 0: 79.37%
	Recall class 1: 75.31%
	Recall class 0: 95.03%
	F1: 83.55%
	ROC AUC Training-> 84.62% Testing-> 83.81%</pre>
	<div class="center"><img src="../images/frauds/cm-lr-tuned.png" alt="" class="vis"><img src="../images/frauds/roc-lr-tuned.png" alt=""></div>
	<div class="desc">Before Tuning Accuracy = 84.63%<br>After Tuning Accuracy = 85.17%
<br>Overfitting is reduced as well.</div>
<h2 class="major" id="rf">Model 3 - Random Forest</h2>
<pre><code>from sklearn.ensemble import RandomForestClassifier
RF = RandomForestClassifier()
#fit the model with training dataset
RF.fit(xtrain, ytrain)
scr(RF, 'RF')
cm(RF)
auc_plot(RF)</code>
	Confusion Matrix Accuracy Score = 88.57%

	Accuracy Score: Training -> 100.00% Testing -> 88.57%

	Overfitting : 11.43%
	Log Loss Training-> 9.992007221626413e-16 Testing -> 3.948323732826286

	Precision class 1: 96.23%
	Precision class 0: 83.08%
	Recall class 1: 80.28%
	Recall class 0: 96.86%
	F1: 87.54%
	ROC AUC Training-> 100.00% Testing-> 93.87%</pre>
	<div class="center"><img src="../images/frauds/cm-rf.png" alt="" class="vis"><img src="../images/frauds/roc-rf.png" alt="" class="vis"></div>
	<div class="desc">The accuracy score is 88.50%, it's higher compared to SVM and Logistic Regression. However, the model is overfitting as the training accuracy score is 100%</div>
	<pre><code># Number of trees in random forest
n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 50)]
# Number of features to consider at every split
max_features = ['auto', 'sqrt']
# Maximum number of levels in tree
max_depth = [int(x) for x in np.linspace(1, 100, num = 10)]
max_depth.append(None)
# Minimum number of samples required to split a node
min_samples_split = [2, 5, 10, 15, 100]
# Minimum number of samples required at each leaf node
min_samples_leaf = [1, 2, 5, 10, 50, 100]
# Method of selecting samples for training each tree
bootstrap = [True, False]

random_grid = {'n_estimators': n_estimators,
				'max_features': max_features,
				'max_depth': max_depth,
				'min_samples_split': min_samples_split,
				'min_samples_leaf': min_samples_leaf,
				'bootstrap': bootstrap}

#implement parameter tuning using randomized search cv and kfold
opt_RF = RandomizedSearchCV(estimator = RF, param_distributions = random_grid, n_iter = 100, cv = kfold, verbose=2, random_state=42, n_jobs = -1)
#fit the model with training dataset
opt_RF.fit(xtrain, ytrain) 
print(opt_RF.best_params_) #best parameter tuning result</code>
	{'n_estimators': 853, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 78, 'bootstrap': False}</pre>
<pre><code>#build the model with hyperparameter tuning
opt_RF = RandomForestClassifier(n_estimators= 600, min_samples_split= 5, min_samples_leaf= 2,max_features= 'auto',max_depth= 6)
opt_RF.fit(xtrain, ytrain)
scr(opt_RF, 'RF_tuned')
cm(opt_RF)
auc_plot(opt_RF)</code>
	Confusion Matrix Accuracy Score = 85.74%

	Accuracy Score: Training -> 86.15% Testing -> 85.74%

	Overfitting : 0.42%
	Log Loss Training-> 4.782934449404927 Testing -> 4.926456581166755

	Precision class 1: 95.55%
	Precision class 0: 79.40%
	Recall class 1: 74.97%
	Recall class 0: 96.51%
	F1: 84.02%
	ROC AUC Training-> 90.47% Testing-> 87.91%</pre>
	<h2 class="major" id="dt">Model 4 - Decision Tree</h2>
	<pre><code>#import the library
from sklearn.tree import DecisionTreeClassifier
#create the model
decTree = DecisionTreeClassifier()
#fit the model with training data
decTree.fit(xtrain, ytrain)
scr(decTree, 'decTree')
cm(decTree)
auc_plot(decTree)</code>
	Confusion Matrix Accuracy Score = 82.90%

	Accuracy Score: Training -> 100.00% Testing -> 82.90%

	Overfitting : 17.10%
	Log Loss Training-> 9.992007221626413e-16 Testing -> 5.904643831404563

	Precision class 1: 82.68%
	Precision class 0: 83.13%
	Recall class 1: 83.25%
	Recall class 0: 82.56%
	F1: 82.97%
	ROC AUC Training-> 100.00% Testing-> 82.90%</pre>
	<div class="center"><img src="../images/frauds/cm-dt.png" alt="" class="vis"><img src="../images/frauds/roc-dt.png" alt="" class="vis"></div>
	<pre><code>#parameter variables
criterion = ['gini', 'entropy']
max_depth = [3,6,9]
min_samples_split = [3,6,9]
min_samples_leaf = [2,4,8]

#put the variables to dict
random_tree = {'criterion': criterion,
				'max_depth': max_depth,
				'min_samples_split': min_samples_split,
				'min_samples_leaf': min_samples_leaf}

#implement hyperparameter tuning to the model
opt_decTree = DecisionTreeClassifier(min_samples_split = 7, min_samples_leaf = 40, max_depth = 5)
#fit the model with training dataset
opt_decTree.fit(xtrain, ytrain) 
#fit the model with training dataset
opt_decTree.fit(xtrain, ytrain) 
print(opt_decTree.best_params_)</code>
	{'min_samples_split': 9, 'min_samples_leaf': 8, 'max_depth': 9, 'criterion': 'gini'}
	
	Confusion Matrix Accuracy Score = 85.81%

	Accuracy Score: Training -> 89.08% Testing -> 85.81%
	
	Overfitting : 3.27%
	Log Loss Training-> 3.773181988317355 Testing -> 4.90261131447784
	
	Precision class 1: 92.43%
	Precision class 0: 80.97%
	Recall class 1: 78.00%
	Recall class 0: 93.61%
	F1: 84.61%
	ROC AUC Training-> 94.47% Testing-> 89.99%</pre>
	<div class="center"><img src="../images/frauds/cm-dt-tuned.png" alt="" class="vis"><img src="../images/frauds/roc-dt-tuned.png" alt="" class="vis"></div>
	<h2 class="major" id="knn">Model 5 - K-Nearest Neighbor</h2>
	<pre><code>from sklearn.neighbors import KNeighborsClassifier

#build the model
neigh = KNeighborsClassifier(n_neighbors=3)
#fit the model with training dataset
neigh.fit(xtrain, ytrain)
scr(neigh, 'KNN')
cm(neigh)
auc_plot(neigh)</code>
	Confusion Matrix Accuracy Score = 82.01%

	Accuracy Score: Training -> 91.15% Testing -> 82.01%

	Overfitting : 9.14%
	Log Loss Training-> 3.0574194329192323 Testing -> 6.214775759201414

	Precision class 1: 83.61%
	Precision class 0: 80.55%
	Recall class 1: 79.63%
	Recall class 0: 84.39%
	F1: 81.57%
	ROC AUC Training-> 97.18% Testing-> 88.02%</pre>
	<div class="center"><img src="../images/frauds/cm-knn.png" alt="" class="vis"><img src="../images/frauds/roc-knn.png" alt="" class="vis">	</div>
	<div class="desc">The accuracy score is 83.15%, it's the lowest accuracy compared to the other algorithms. Also, this model has overfitting problem.</div>
	<pre><code>tuning_params = {
	'n_neighbors' : [71,75,77,83], #from the plot above
	"leaf_size":[5,10,20,30],
	"p":[1,2]
}

#implement hyperparameter tuning to the model
opt_knn = GridSearchCV(neigh, param_grid = tuning_params, cv = kfold, verbose = 1, n_jobs = -1)
#fit the model with training dataset
opt_knn.fit(xtrain, ytrain) 
print(opt_knn.best_params_)
scr(opt_knn, 'knn_tuned')
cm(opt_knn)
auc_plot(opt_knn)</code>
	{'leaf_size': 5, 'n_neighbors': 83, 'p': 1}

	Confusion Matrix Accuracy Score = 85.24%

	Accuracy Score: Training -> 85.66% Testing -> 85.24%
	
	Overfitting : 0.43%
	Log Loss Training-> 4.951649723316238 Testing -> 5.099414020217411
	
	Precision class 1: 96.96%
	Precision class 0: 78.19%
	Recall class 1: 72.76%
	Recall class 0: 97.72%
	F1: 83.13%
	ROC AUC Training-> 90.07% Testing-> 88.92%</pre>
	<div class="center"><img src="../images/frauds/cm-knn-tuned.png" alt="" class="vis"><img src="../images/frauds/roc-knn-tuned.png" alt="" class="vis"></div>
	<h2 class="major" id="ann">Model 6 - Artificial Neural Network</h2>
	<div class="desc">Let's say we want to split the data in 60:20:20 for train:valid:test dataset. In the first step we will split the data in training and remaining dataset.
		Since we want the valid and test size to be equal (10% each of overall data). We have to define valid_size=0.5 (that is 50% of remaining data)
	</div>
	<pre><code>Xtrain, xrem, Ytrain, yrem = train_test_split(xtrain,ytrain, train_size=0.6)
xvalid, xtest, yvalid, ytest = train_test_split(xrem,yrem, test_size=0.5)	
#build the model
ann=keras.Sequential([keras.layers.Dense(20,input_shape=(14,),activation='relu'),
                       keras.layers.Dense(1,activation='sigmoid'),])
ann.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy', tf.keras.metrics.AUC()])
#train the model
history=ann.fit(Xtrain,Ytrain,epochs=30,validation_data=(xvalid,yvalid))
plot_learningCurve(history,30)
	</code></pre>
	<div class="center"><img src="../images/frauds/ann-accuracy.png" alt="" class="vis"><img src="../images/frauds/ann-loss.png" alt="" class="vis"></div>
	<pre><code>testeval1 = ann.evaluate(xtest, ytest)
traineval1 = ann.evaluate(xvalid, yvalid)
yprediction=ann.predict(xtest)
ypred=[]
for element in yprediction:
    if element>0.5:
        ypred.append(1)
    else:
        ypred.append(0)

#plot confusion matrix
cmt =tf.math.confusion_matrix(labels=ytest,predictions=ypred)
plt.figure(figsize=(7,5))
sns.heatmap(cmt,annot=True,fmt='d')
plt.xlabel('predicted')
plt.ylabel('actual')
#print the metrics score
calc(ann, 'ann', testeval1, traineval1, cmt) 
	</code>
	Confusion Matrix Accuracy Score = 86.24%

	Accuracy Score: Training -> 85.09% Testing -> 86.24%
	
	Overfitting : -1.15%
	Log Loss Training-> 0.35751211643218994 Testing -> 0.3230932652950287
	
	Precision class 1: 96.95%
	Precision class 0: 79.77%
	Recall class 1: 74.30%
	Recall class 0: 97.75%
	F1: 84.13%
	ROC AUC Training-> 90.58% Testing-> 91.87%</pre>
	<div class="center"><img src="../images/frauds/cm-ann.png" alt=""></div>
	<pre><code>opt_ann=create_my_model1()
#train the model
history=opt_ann.fit(Xtrain,Ytrain,epochs=50,batch_size = 15,validation_data=(xvalid,yvalid))
plot_learningCurve(history,50)</code></pre>
<div class="center"><img src="../images/frauds/ann-accuracy-tuned.png" alt="" class="vis"><img src="../images/frauds/ann-loss-tuned.png" alt="" class="vis"></div>
<pre><code>calc(opt_ann, 'ann_tuned', testeval, traineval, cm1)
cm1 =tf.math.confusion_matrix(labels=ytest,predictions=ypred1)
plt.figure(figsize=(7,5))
sns.heatmap(cm1,annot=True,fmt='d')
plt.xlabel('predicted')
plt.ylabel('actual')</code>
	Confusion Matrix Accuracy Score = 86.72%

	Accuracy Score: Training -> 85.09% Testing -> 86.24%

	Overfitting : -1.15%
	Log Loss Training-> 0.35751211643218994 Testing -> 0.3230932652950287

	Precision class 1: 96.36%
	Precision class 0: 80.65%
	Recall class 1: 75.81%
	Recall class 0: 97.24%
	F1: 84.86%
	ROC AUC Training-> 90.58% Testing-> 91.87%</pre>
<div class="center"><img src="../images/frauds/cm-ann-tuned.png" alt=""></div>
<h2 class="major">Model 7 - Convolutional Neural Networks</h2>
<pre><code>epochs=20
cnn=Sequential()
cnn.add(Conv1D(32,2, activation='relu',input_shape=Xtrain[0].shape))
cnn.add(BatchNormalization())
cnn.add(Dropout(0.2))

cnn.add(Conv1D(64,2, activation='relu'))
cnn.add(BatchNormalization())
cnn.add(Dropout(0.5))

cnn.add(Flatten())
cnn.add(Dense(64,activation='relu'))
cnn.add(Dropout(0.5))

cnn.add(Dense(1,activation='sigmoid'))
cnn.compile(optimizer=Adam(learning_rate=0.0001),loss='binary_crossentropy',metrics=['accuracy',
	tf.keras.metrics.AUC()])

	history=cnn.fit(Xtrain,Ytrain,epochs=epochs,validation_data=(xvalid,yvalid))
plot_learningCurve(history,epochs)</code></pre>
<div class="center"><img src="../images/frauds/cnn-accuracy.png" alt="" class="vis"><img src="../images/frauds/cnn-loss.png" alt=""></div>
<pre><code>cntesteval = cnn.evaluate(xtest, ytest)
cntraineval = cnn.evaluate(Xtrain,Ytrain)
cnypredict=cnn.predict(xtest)
ypred2=[]
for element in cnypredict:
    if element>0.5:
        ypred2.append(1)
    else:
        ypred2.append(0)
	
cm2 =tf.math.confusion_matrix(labels=ytest,predictions=ypred2)
plt.figure(figsize=(7,5))
sns.heatmap(cm2,annot=True,fmt='d')
plt.xlabel('predicted')
plt.ylabel('actual')

calc(cnn, 'cnn', cntesteval, cntraineval, cm2)</code>
	Confusion Matrix Accuracy Score = 86.68%

	Accuracy Score: Training -> 86.53% Testing -> 86.68%

	Overfitting : -0.15%
	Log Loss Training-> 0.35620877146720886 Testing -> 0.3592900037765503

	Precision class 1: 96.99%
	Precision class 0: 80.35%
	Recall class 1: 75.21%
	Recall class 0: 97.75%
	F1: 84.72%
	ROC AUC Training-> 90.13% Testing-> 89.15%</pre>
<div class="center"><img src="../images/frauds/cm-cnn.png" alt=""></div>
<pre><code>epochs=50
cnnmax=Sequential()
cnnmax.add(Conv1D(32,2, activation='relu',input_shape=Xtrain[0].shape))
cnnmax.add(BatchNormalization())
cnnmax.add(MaxPool1D(2))
cnnmax.add(Dropout(0.2))

cnnmax.add(Conv1D(64,2, activation='relu'))
cnnmax.add(BatchNormalization())
cnnmax.add(MaxPool1D(2))
cnnmax.add(Dropout(0.5))

cnnmax.add(Flatten())
cnnmax.add(Dense(64,activation='relu'))
cnnmax.add(Dropout(0.5))

cnnmax.add(Dense(1,activation='sigmoid'))

cnnmax.compile(optimizer=Adam(learning_rate=0.0001),loss='binary_crossentropy',metrics=['accuracy',
	tf.keras.metrics.AUC()])
history2=cnnmax.fit(Xtrain,Ytrain,epochs=100,validation_data=(xvalid,yvalid))

plot_learningCurve(history2,100)</code></pre>

<div class="center"><img src="../images/frauds/cnn-accuracy-tuned.png" alt="" class="vis"><img src="../images/frauds/cnn-loss-tuned.png" alt="" class="vis"></div>

<pre><code>calc(cnn, 'cnn_tuned', maxtesteval, maxtraineval, cm3)
#plot confusion matrix
cm3 =tf.math.confusion_matrix(labels=ytest,predictions=ypred3)
plt.figure(figsize=(7,5))
sns.heatmap(cm3,annot=True,fmt='d')
plt.xlabel('predicted')
plt.ylabel('actual')</code>
	Confusion Matrix Accuracy Score = 77.28%

	Accuracy Score: Training -> 78.63% Testing -> 77.28%

	Overfitting : 1.35%
	Log Loss Training-> 0.46808817982673645 Testing -> 0.48547038435935974

	Precision class 1: 89.22%
	Precision class 0: 71.24%
	Recall class 1: 61.12%
	Recall class 0: 92.88%
	F1: 72.54%
	ROC AUC Training-> 85.53% Testing-> 83.94%</pre>
	<div class="center"><img src="../images/frauds/cm-cnn-tuned.png" alt=""></div>

	<h2 class="major" id="conclusion">Conclusion</h2>
	<pre><code>scoring = pd.DataFrame(score, columns = ['algo','c_matrix','acc_test','acc_train','overfit', 'loss_test',
	'loss_train', 'prec1', 'prec0', 'recall1','recall0', 'F1', 'roctest', 'roctrain'])</code></pre>
	<div class="table-wrapper">
		<table>
			<thead>
				<tr style="text-align: right;">
				  <th></th>
				  <th>algo</th>
				  <th>c_matrix</th>
				  <th>acc_test</th>
				  <th>acc_train</th>
				  <th>overfit</th>
				  <th>loss_test</th>
				  <th>loss_train</th>
				  <th>prec1</th>
				  <th>prec0</th>
				  <th>recall1</th>
				  <th>recall0</th>
				  <th>F1</th>
				  <th>roctest</th>
				  <th>roctrain</th>
				</tr>
			  </thead>
			  <tbody>
				<tr>
				  <th>0</th>
				  <td>SVM1</td>
				  <td>86.219997</td>
				  <td>86.219997</td>
				  <td>86.936570</td>
				  <td>0.716574</td>
				  <td>4.759453</td>
				  <td>4.511956e+00</td>
				  <td>97.252252</td>
				  <td>79.361523</td>
				  <td>74.551105</td>
				  <td>97.892919</td>
				  <td>84.401876</td>
				  <td>88.385672</td>
				  <td>91.927927</td>
				</tr>
				<tr>
				  <th>1</th>
				  <td>SVM_tuned</td>
				  <td>87.653255</td>
				  <td>87.653255</td>
				  <td>93.072311</td>
				  <td>5.419056</td>
				  <td>4.264439</td>
				  <td>2.392745e+00</td>
				  <td>93.153937</td>
				  <td>83.394608</td>
				  <td>81.284530</td>
				  <td>94.024180</td>
				  <td>86.815416</td>
				  <td>93.105302</td>
				  <td>97.606863</td>
				</tr>
				<tr>
				  <th>2</th>
				  <td>Logreg</td>
				  <td>84.631324</td>
				  <td>84.631324</td>
				  <td>85.064022</td>
				  <td>0.432697</td>
				  <td>5.308179</td>
				  <td>5.158730e+00</td>
				  <td>92.036882</td>
				  <td>79.441997</td>
				  <td>75.828729</td>
				  <td>93.436960</td>
				  <td>83.150322</td>
				  <td>84.346487</td>
				  <td>85.189161</td>
				</tr>
				<tr>
				  <th>3</th>
				  <td>logreg_tuned</td>
				  <td>85.166638</td>
				  <td>85.166638</td>
				  <td>85.537710</td>
				  <td>0.371072</td>
				  <td>5.123282</td>
				  <td>4.995118e+00</td>
				  <td>93.806452</td>
				  <td>79.371033</td>
				  <td>75.310773</td>
				  <td>95.025907</td>
				  <td>83.547213</td>
				  <td>83.811320</td>
				  <td>84.624693</td>
				</tr>
				<tr>
				  <th>4</th>
				  <td>RF</td>
				  <td>88.568468</td>
				  <td>88.568468</td>
				  <td>100.000000</td>
				  <td>11.431532</td>
				  <td>3.948324</td>
				  <td>9.992007e-16</td>
				  <td>96.233444</td>
				  <td>83.081481</td>
				  <td>80.283149</td>
				  <td>96.856649</td>
				  <td>87.537651</td>
				  <td>93.873451</td>
				  <td>100.000000</td>
				</tr>
				<tr>
				  <th>5</th>
				  <td>RF_tuned</td>
				  <td>88.982905</td>
				  <td>88.982905</td>
				  <td>100.000000</td>
				  <td>11.017095</td>
				  <td>3.805185</td>
				  <td>9.992007e-16</td>
				  <td>95.597738</td>
				  <td>84.042232</td>
				  <td>81.733425</td>
				  <td>96.234888</td>
				  <td>88.123604</td>
				  <td>94.519837</td>
				  <td>100.000000</td>
				</tr>
				<tr>
				  <th>6</th>
				  <td>RF_tuned</td>
				  <td>85.736488</td>
				  <td>85.736488</td>
				  <td>86.152024</td>
				  <td>0.415537</td>
				  <td>4.926457</td>
				  <td>4.782934e+00</td>
				  <td>95.554577</td>
				  <td>79.397556</td>
				  <td>74.965470</td>
				  <td>96.511226</td>
				  <td>84.017028</td>
				  <td>87.914007</td>
				  <td>90.470434</td>
				</tr>
				<tr>
				  <th>7</th>
				  <td>decTree</td>
				  <td>82.904507</td>
				  <td>82.904507</td>
				  <td>100.000000</td>
				  <td>17.095493</td>
				  <td>5.904644</td>
				  <td>9.992007e-16</td>
				  <td>82.681756</td>
				  <td>83.130435</td>
				  <td>83.252762</td>
				  <td>82.556131</td>
				  <td>82.966277</td>
				  <td>82.904447</td>
				  <td>100.000000</td>
				</tr>
				<tr>
				  <th>8</th>
				  <td>decTree_tuned</td>
				  <td>85.805560</td>
				  <td>85.805560</td>
				  <td>89.075568</td>
				  <td>3.270008</td>
				  <td>4.902611</td>
				  <td>3.773182e+00</td>
				  <td>92.430442</td>
				  <td>80.968031</td>
				  <td>78.004144</td>
				  <td>93.609672</td>
				  <td>84.606742</td>
				  <td>89.989355</td>
				  <td>94.472079</td>
				</tr>
				<tr>
				  <th>9</th>
				  <td>decTree_tuned</td>
				  <td>85.391124</td>
				  <td>85.391124</td>
				  <td>86.129820</td>
				  <td>0.738696</td>
				  <td>5.045744</td>
				  <td>4.790606e+00</td>
				  <td>94.759825</td>
				  <td>79.263068</td>
				  <td>74.930939</td>
				  <td>95.854922</td>
				  <td>83.686849</td>
				  <td>88.834197</td>
				  <td>90.058876</td>
				</tr>
				<tr>
				  <th>10</th>
				  <td>KNN</td>
				  <td>82.006562</td>
				  <td>82.006562</td>
				  <td>91.147954</td>
				  <td>9.141392</td>
				  <td>6.214776</td>
				  <td>3.057419e+00</td>
				  <td>83.611313</td>
				  <td>80.547313</td>
				  <td>79.627072</td>
				  <td>84.386874</td>
				  <td>81.570570</td>
				  <td>88.016352</td>
				  <td>97.184685</td>
				</tr>
				<tr>
				  <th>11</th>
				  <td>knn_tuned</td>
				  <td>85.287515</td>
				  <td>85.287515</td>
				  <td>85.663533</td>
				  <td>0.376018</td>
				  <td>5.081522</td>
				  <td>4.951650e+00</td>
				  <td>96.794872</td>
				  <td>78.319933</td>
				  <td>72.997238</td>
				  <td>97.582038</td>
				  <td>83.228346</td>
				  <td>89.064966</td>
				  <td>90.235731</td>
				</tr>
				<tr>
				  <th>12</th>
				  <td>knn_tuned</td>
				  <td>85.235711</td>
				  <td>85.235711</td>
				  <td>85.663533</td>
				  <td>0.427823</td>
				  <td>5.099414</td>
				  <td>4.951650e+00</td>
				  <td>96.962724</td>
				  <td>78.192371</td>
				  <td>72.755525</td>
				  <td>97.720207</td>
				  <td>83.132768</td>
				  <td>88.920260</td>
				  <td>90.068988</td>
				</tr>
				<tr>
				  <th>13</th>
				  <td>ann</td>
				  <td>86.237514</td>
				  <td>86.237514</td>
				  <td>85.085124</td>
				  <td>-1.152390</td>
				  <td>0.323093</td>
				  <td>3.575121e-01</td>
				  <td>96.951819</td>
				  <td>79.774614</td>
				  <td>74.302939</td>
				  <td>97.747093</td>
				  <td>84.129693</td>
				  <td>91.869640</td>
				  <td>90.576106</td>
				</tr>
				<tr>
				  <th>14</th>
				  <td>ann_tuned</td>
				  <td>86.718461</td>
				  <td>86.237514</td>
				  <td>85.085124</td>
				  <td>-1.152390</td>
				  <td>0.323093</td>
				  <td>3.575121e-01</td>
				  <td>96.360153</td>
				  <td>80.650995</td>
				  <td>75.810098</td>
				  <td>97.238372</td>
				  <td>84.858709</td>
				  <td>91.869640</td>
				  <td>90.576106</td>
				</tr>
				<tr>
				  <th>15</th>
				  <td>cnn</td>
				  <td>86.681465</td>
				  <td>86.681467</td>
				  <td>86.528498</td>
				  <td>-0.152969</td>
				  <td>0.359290</td>
				  <td>3.562088e-01</td>
				  <td>96.987366</td>
				  <td>80.346476</td>
				  <td>75.207234</td>
				  <td>97.747093</td>
				  <td>84.719864</td>
				  <td>89.148206</td>
				  <td>90.132415</td>
				</tr>
				<tr>
				  <th>16</th>
				  <td>cnn_tuned</td>
				  <td>77.284499</td>
				  <td>77.284497</td>
				  <td>78.633112</td>
				  <td>1.348615</td>
				  <td>0.485470</td>
				  <td>4.680882e-01</td>
				  <td>89.218922</td>
				  <td>71.237458</td>
				  <td>61.115298</td>
				  <td>92.877907</td>
				  <td>72.540250</td>
				  <td>83.936465</td>
				  <td>85.533202</td>
				</tr>
			  </tbody>
		</table>
	</div>
	<div class="desc">Seven algorithms from Machine Learning and Deep Learning were conducted to determine the most predictive classifier for credit card fraud detection. These projects constructed from two datasets and combine into one, with extreme imbalance classification problems that solved using Imblearnâ€™s Random Under Sampling to make the class is balanced. Some models have a high accuracy score; however, the overfitting cannot be avoided. For example, Decision Tree and Random Forest have a high accuracy score of 100% in the training phase yet their overfitting percentage is more than 10%. <br><br>

		Hyperparameter tuning, K-Fold cross-validation and validation curves are applied to cope with the overfitting problem and to improve the accuracy. As a result, the overfit in Random Forest and Decision Tree are dropped by almost 10% by changing some of the parameters, and the accuracy score is also increased for Decision Tree from 82.90% to 85.39%. <br><br>
		
		For future benefits, we selected three algorithms with the lowest percentage of overfitting as they will generalise well to new data. If the model can generalise the data well, it also could perform the classification or prediction task that was intended for. Consequently, we picked Logistic Regression, Decision Trees and CNN as our final algorithm for the credit card fraud detection problem.</div>
								</div>
							</div>

					</section>

								<!-- Footer -->
								<section id="footer">
									<div class="inner">
										<h2 class="major">Get in touch</h2>
										<section>
											<ul class="contact">
												<li class="icon solid fa-envelope"><a href="mailto:hello@devyratnasari.com">hello@devyratnasari.com</a></li>
											</ul>
											<h3>Let's Connect!</h3>
											<ul class="icons">
												<li><a href="https://github.com/devyratnasari" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
												<li><a href="https://linkedin.com/in/devy-ratnasari" class="icon brands fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
											</ul>
										</section>
										<ul class="copyright">
											<li>&copy; Devy Ratnasari</li>
											<li>Templates: <a href="http://html5up.net">HTML5 UP</a></li>
											<li>Images: &copy; Devy Ratnasari</li>
										</ul>
									</div>
								</section>

			</div>

		<!-- Scripts -->
			<script src="../assets/js/jquery.min.js"></script>
			<script src="../assets/js/jquery.scrollex.min.js"></script>
			<script src="../assets/js/browser.min.js"></script>
			<script src="../assets/js/breakpoints.min.js"></script>
			<script src="../assets/js/util.js"></script>
			<script src="../assets/js/main.js"></script>

	</body>
</html>